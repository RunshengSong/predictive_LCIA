{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create acid model with full descs without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/runshengsong/anaconda/envs/tensorflow/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\") # append to system path\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib.patches import Rectangle\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_lcia_data(descs_p, target_p):\n",
    "    X = pd.read_csv(descs_p,header=0,index_col=None)\n",
    "    X = X.fillna(0)\n",
    "    y = pd.read_csv(target_p,header=0,index_col=None)\n",
    "    return X.values,y.values\n",
    "\n",
    "def mre(true_y,pred_y):\n",
    "    ## Note: does not handle mix 1d representation\n",
    "    #if _is_1d(y_true): \n",
    "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "\n",
    "    return np.mean(np.abs(np.subtract(true_y, pred_y) / true_y)) * 100\n",
    "\n",
    "descs_p = '../data/descs/feature_selection/descs_Mar08_58.csv'\n",
    "target_p = '../data/target/full/acidification.csv'\n",
    "X,y = load_lcia_data(descs_p, target_p)\n",
    "\n",
    "trn_X, val_X, trn_y, val_y = cross_validation.train_test_split(\n",
    "    X, y, test_size=0.1, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 56) (149, 1)\n"
     ]
    }
   ],
   "source": [
    "print trn_X.shape, trn_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing -- only scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 56)\n"
     ]
    }
   ],
   "source": [
    "## Standard Scaler\n",
    "this_scaler = StandardScaler()\n",
    "trn_X = this_scaler.fit_transform(trn_X)\n",
    "val_X = this_scaler.transform(val_X)\n",
    "\n",
    "print trn_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 1\n"
     ]
    }
   ],
   "source": [
    "def init_weights(shape):\n",
    "    weights = tf.random_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "num_descs = trn_X.shape[1]\n",
    "num_target = trn_y.shape[1]\n",
    "\n",
    "print num_descs,num_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### \n",
    "##Define model structure\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,num_descs])\n",
    "y = tf.placeholder(tf.float32,shape=[None,num_target])\n",
    "\n",
    "tf.add_to_collection('X',X)\n",
    "tf.add_to_collection('y',y)\n",
    "\n",
    "#First layer\n",
    "w1 = init_weights((num_descs,128)) \n",
    "b1 = bias_variable([128])\n",
    "l1 = tf.add(tf.matmul(X,w1),b1)\n",
    "l1 = tf.nn.sigmoid(l1)\n",
    "\n",
    "# # Second layer\n",
    "# w2 = init_weights((128,128))\n",
    "# b2 = bias_variable([128])\n",
    "# l2 = tf.add(tf.matmul(l1,w2),b2)\n",
    "# l2 = tf.nn.sigmoid(l2)\n",
    "\n",
    "# # Third layer\n",
    "# w3 = init_weights((512,512))\n",
    "# b3 = bias_variable([512])\n",
    "# l3 = tf.add(tf.matmul(l2,w3),b3)\n",
    "# l3 = tf.nn.relu(l3)\n",
    "\n",
    "#Output layer\n",
    "w_out = init_weights((128,num_target))\n",
    "b_out = bias_variable([num_target])\n",
    "l_out = tf.matmul(l1,w_out) + b_out #no nonlinarity\n",
    "\n",
    "pred = l_out\n",
    "tf.add_to_collection('pred',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#static parameters\n",
    "BATCH_SIZE = 1\n",
    "BETA = 0.01 #regularization weights\n",
    "\n",
    "#Define loss and optimizer \n",
    "#Add regularization term\n",
    "regularizers = tf.nn.l2_loss(w1) + tf.nn.l2_loss(w_out)\n",
    "cost = tf.reduce_mean(tf.square(pred - y) + BETA*regularizers)\n",
    "\n",
    "#Gridient Descent Optimizer\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Epoch = 1,Cost = 0.37,Training Accuracy = 0.26, Validation Accuracy = 0.26, Validation MRE =100.50\n",
      "Epoch = 101,Cost = 0.19,Training Accuracy = 0.76, Validation Accuracy = 0.72, Validation MRE =60.16\n",
      "Epoch = 201,Cost = 0.17,Training Accuracy = 0.77, Validation Accuracy = 0.72, Validation MRE =60.03\n",
      "Epoch = 301,Cost = 0.17,Training Accuracy = 0.77, Validation Accuracy = 0.72, Validation MRE =60.13\n",
      "Epoch = 401,Cost = 0.17,Training Accuracy = 0.77, Validation Accuracy = 0.72, Validation MRE =60.24\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tst_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e5c9e6be8843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfinal_pred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# prediction on the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mfinal_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtst_X\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_pred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tst_X' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "#Start Training\n",
    "costs=[]\n",
    "\n",
    "#save the model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(500):\n",
    "        for i in range(0, len(trn_X),BATCH_SIZE):\n",
    "            _, c = sess.run([optimizer,cost], feed_dict={X:trn_X[i:i+BATCH_SIZE], y:trn_y[i:i+BATCH_SIZE]})\n",
    "        \n",
    "        trn_score = r2_score(trn_y,sess.run(pred, feed_dict={X:trn_X, y:trn_y}))\n",
    "        val_score = r2_score(val_y,sess.run(pred, feed_dict={X:val_X, y:val_y}))     \n",
    "        val_mre = mre(val_y,sess.run(pred,feed_dict={X:val_X,y:val_y}))\n",
    "        \n",
    "        costs.append(val_score)\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch = %d,Cost = %.2f,Training Accuracy = %.2f, Validation Accuracy = %.2f, Validation MRE =%.2f\" % (epoch + 1,c,trn_score,val_score,val_mre))\n",
    "  \n",
    "    # final pred on the validation set\n",
    "    final_pred_val = sess.run(pred,feed_dict={X:val_X})\n",
    "    # prediction on the testing set\n",
    "\n",
    "    plt.plot(costs)\n",
    "    plt.show()\n",
    "    \n",
    "#     save_path = saver.save(sess, \"../nets/acidification/acidification.ckpt\")\n",
    "#     saver.export_meta_graph(\"../nets/acidification/CED_apr4.meta\")\n",
    "#     print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
