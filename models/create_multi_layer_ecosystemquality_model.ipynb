{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multi-Layer NN model using tensorflow\n",
    "\n",
    "So I can adjust the parameters as I want..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\") # append to system path\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib.patches import Rectangle\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_lcia_data(descs_p, target_p):\n",
    "    X = pd.read_csv(descs_p,header=0,index_col=None)\n",
    "    X = X.fillna(0)\n",
    "    y = pd.read_csv(target_p,header=0,index_col=None)\n",
    "    return X.values,y.values\n",
    "\n",
    "def mre(true_y,pred_y):\n",
    "    ## Note: does not handle mix 1d representation\n",
    "    #if _is_1d(y_true): \n",
    "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "\n",
    "    return np.mean(np.abs((true_y - pred_y) / true_y)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training data\n",
    "The training data has 156 chemicals now. The rest 10 chemicals are test data\n",
    "We also split the training and validation data here\n",
    "We use smaller set (10%) to be the valdiation set (16 chemicals), as the limited size of training chemicals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "descs_p = '../data/descs/train/descs_Mar08_3839_train.csv'\n",
    "target_p = '../data/target/train/ecosystemquality_train.csv'\n",
    "X,y = load_lcia_data(descs_p, target_p)\n",
    "\n",
    "trn_X, val_X, trn_y, val_y = cross_validation.train_test_split(\n",
    "    X, y, test_size=0.1, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 3839) (140, 1)\n"
     ]
    }
   ],
   "source": [
    "print trn_X.shape, trn_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descs_tst = '../data/descs/test/descs_Mar08_3839_test.csv'\n",
    "target_tst = '../data/target/test/ecosystemquality_test.csv'\n",
    "tst_X,tst_y = load_lcia_data(descs_tst, target_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Normalization + PCA or Just Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Standard Scaler\n",
    "this_scaler = StandardScaler()\n",
    "trn_X = this_scaler.fit_transform(trn_X)\n",
    "val_X = this_scaler.transform(val_X)\n",
    "tst_X = this_scaler.transform(tst_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 3839)\n",
      "(10, 3839)\n",
      "[ -1.39123274e-16  -7.31161163e-16   5.43612774e-16 ...,   0.00000000e+00\n",
      "   2.02219194e-17   8.56457762e-17] [ 1.  1.  1. ...,  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print trn_X.shape\n",
    "print tst_X.shape\n",
    "print np.mean(trn_X,0),np.std(trn_X,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### PCA, don't run them together\n",
    "# normalize the data first\n",
    "pca = PCA(n_components = 60)\n",
    "\n",
    "trn_X = pca.fit_transform(trn_X)\n",
    "val_X = pca.transform(val_X)\n",
    "tst_X = pca.transform(tst_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 60) (10, 60)\n",
      "0.955948685709\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print trn_X.shape, tst_X.shape\n",
    "print(reduce(lambda x,y:x+y,pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(trn_X[:,0],trn_X[:,1])\n",
    "plt.scatter(tst_X[:,0],tst_X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(trn_y, 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the Log Scale of Training Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_y = np.log(trn_y)\n",
    "val_y = np.log(val_y)\n",
    "tst_y = np.log(tst_y)\n",
    "\n",
    "n, bins, patches = plt.hist(tst_y,50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../nets/ecosystemquality/pca.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(this_scaler, '../nets/ecosystemquality/scaler.pkl') \n",
    "joblib.dump(pca, '../nets/ecosystemquality/pca.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 1\n"
     ]
    }
   ],
   "source": [
    "def init_weights(shape):\n",
    "    weights = tf.random_normal(shape,stddev = 0.1)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "num_descs = trn_X.shape[1]\n",
    "num_target = trn_y.shape[1]\n",
    "\n",
    "print num_descs,num_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### \n",
    "##Define model structure\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,num_descs])\n",
    "y = tf.placeholder(tf.float32,shape=[None,num_target])\n",
    "# add to collection\n",
    "tf.add_to_collection('X',X)\n",
    "tf.add_to_collection('y',y)\n",
    "\n",
    "# First layer\n",
    "w1 = init_weights((num_descs,128)) \n",
    "b1 = bias_variable([128])\n",
    "l1 = tf.add(tf.matmul(X,w1),b1)\n",
    "l1 = tf.nn.sigmoid(l1)\n",
    "\n",
    "# Second layer\n",
    "w2 = init_weights((128,128)) \n",
    "b2 = bias_variable([128])\n",
    "l2 = tf.add(tf.matmul(l1,w2),b2)\n",
    "l2 = tf.nn.sigmoid(l2)\n",
    "\n",
    "# Third layer\n",
    "# w3 = init_weights((128,128)) \n",
    "# b3 = bias_variable([128])\n",
    "# l3 = tf.add(tf.matmul(l2,w3),b3)\n",
    "# l3 = tf.nn.sigmoid(l3)\n",
    "\n",
    "# # Fourth layer\n",
    "# w4 = init_weights((64,64)) \n",
    "# b4 = bias_variable([64])\n",
    "# l4 = tf.add(tf.matmul(l3,w4),b4)\n",
    "# l4 = tf.nn.sigmoid(l4)\n",
    "\n",
    "# # Fifth layer\n",
    "# w5 = init_weights((64,64)) \n",
    "# b5 = bias_variable([64])\n",
    "# l5 = tf.add(tf.matmul(l4,w5),b5)\n",
    "# l5 = tf.nn.sigmoid(l5)\n",
    "\n",
    "# Output layer\n",
    "w_out = init_weights((128,num_target))\n",
    "b_out = bias_variable([num_target])\n",
    "l_out = tf.matmul(l2,w_out) + b_out #no nonlinarity\n",
    "\n",
    "pred = l_out\n",
    "tf.add_to_collection('pred',pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#static parameters\n",
    "BATCH_SIZE = 1\n",
    "BETA = 0.01 #regularization weights\n",
    "\n",
    "#Define loss and optimizer \n",
    "#Add regularization term\n",
    "# regularizers = tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2) + tf.nn.l2_loss(w3) + tf.nn.l2_loss(w_out)\n",
    "regularizers = tf.nn.l2_loss(w1) + tf.nn.l2_loss(w2) + tf.nn.l2_loss(w_out)\n",
    "cost = tf.reduce_mean(tf.square(pred - y) + BETA*regularizers)\n",
    "\n",
    "#Gridient Descent Optimizer\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate = 0.005).minimize(cost)\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Epoch = 1,Cost = 1.25,Training Accuracy = -0.01, Validation Accuracy = -0.04, Validation MRE =83.35\n",
      "Epoch = 51,Cost = 1.03,Training Accuracy = 0.74, Validation Accuracy = 0.38, Validation MRE =49.55\n",
      "Epoch = 101,Cost = 0.78,Training Accuracy = 0.83, Validation Accuracy = 0.40, Validation MRE =53.90\n",
      "[ 0.00012772] [ 0.00023961]\n",
      "[ 0.00012991] [  5.24778334e-05]\n",
      "[ 0.00011437] [  9.89937107e-05]\n",
      "[ 0.00040355] [ 0.00020012]\n",
      "[ 0.00036248] [ 0.00024178]\n",
      "[  6.37000000e-05] [  3.59396217e-05]\n",
      "[  8.74000000e-05] [ 0.00021672]\n",
      "[  1.17000000e-05] [  2.61446858e-05]\n",
      "[  9.31000000e-05] [  5.93502773e-05]\n",
      "[  2.41000000e-05] [  3.00095253e-05]\n",
      "Model saved in file: ../nets/ecosystemquality/ecosystemquality_apr4.ckpt\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "#Start Training\n",
    "costs=[]\n",
    "\n",
    "#save the model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(120):\n",
    "        for i in range(0, len(trn_X),BATCH_SIZE):\n",
    "            _, c = sess.run([optimizer,cost], feed_dict={X:trn_X[i:i+BATCH_SIZE], y:trn_y[i:i+BATCH_SIZE]})\n",
    "        \n",
    "        trn_score = r2_score(np.exp(trn_y),np.exp(sess.run(pred, feed_dict={X:trn_X, y:trn_y})))\n",
    "        val_score = r2_score(np.exp(val_y),np.exp(sess.run(pred, feed_dict={X:val_X, y:val_y})))     \n",
    "        val_mre = mre(np.exp(val_y),np.exp(sess.run(pred,feed_dict={X:val_X,y:val_y})))\n",
    "        \n",
    "        costs.append(val_score)\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Epoch = %d,Cost = %.2f,Training Accuracy = %.2f, Validation Accuracy = %.2f, Validation MRE =%.2f\" % (epoch + 1,c,trn_score,val_score,val_mre))\n",
    "  \n",
    "    # final pred on the validation set\n",
    "    final_pred_val = sess.run(pred,feed_dict={X:val_X})\n",
    "    # prediction on the testing set\n",
    "    final_pred_test = sess.run(pred,feed_dict={X:tst_X})\n",
    "    \n",
    "    # convert it back \n",
    "    \n",
    "    for (y,y_hat) in zip(np.exp(tst_y),np.exp(final_pred_test)):\n",
    "        print y,y_hat\n",
    "    \n",
    "    \n",
    "    plt.plot(costs)\n",
    "    plt.show()\n",
    "    \n",
    "    save_path = saver.save(sess, \"../nets/ecosystemquality/ecosystemquality_apr4.ckpt\")\n",
    "    saver.export_meta_graph(\"../nets/ecosystemquality/ecosystemquality_apr4.meta\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the value back, remember only run this once \n",
    "tst_y = np.exp(tst_y) \n",
    "final_pred_test = np.exp(final_pred_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.416994013107\n"
     ]
    }
   ],
   "source": [
    "MRE_this = mre(tst_y, final_pred_test)\n",
    "R2_this = r2_score(tst_y, final_pred_test)\n",
    "print R2_this\n",
    "MRE_label = 'MRE: ' + str(round(MRE_this,2))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "est = plt.plot(tst_y, final_pred_test,'o', label='estimated values')\n",
    "\n",
    "max_val = max(max(tst_y),max(final_pred_test))\n",
    "plt.ylim([0,max_val])\n",
    "plt.xlim([0,max_val])\n",
    "\n",
    "thisLine = plt.plot(np.append(0,max_val), np.append(0,max_val), label='perfect prediction line')\n",
    "\n",
    "plt.plot([],[],linewidth=0, label=MRE_label)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
